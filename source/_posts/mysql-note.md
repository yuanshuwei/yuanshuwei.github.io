---
title: mysql笔记
date: 2019-06-26 11:43:50
tags: mysql
categories: mysql
---
mysql笔记
<!--more-->
mysql基础架构
---
![](/images/mysql-construct.png)
- Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

日志系统
---
### redo log(innoDB特有)
- 当一条记录需要更新的时候，innoDB先把记录写到redo log，并更新内存，这个时候更新就算完成了，innoDB会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是系统空闲的时候
- redo log是固定大小的，从头开始写，写到末尾又回到开头循环写。在这个环上一个标记写位置的指针，一个标记当前擦除位置的指针，当快追上的时候就开始移动指针删除数据。
- 有了redo log，就可以保证数据库发生异常重启，之前的记录不会丢失，这个能力称为**crash-safe**

### binlog(归档日志)
- mysql server层实现的
- redo log是物理日志，

#### 两段提交
- 写入redo log处理prepare阶段
- 写入bin log 提交事务，处于commit状态

#### 为什么两段提交？
使得bin log与 redo log一致
redo log: 少一条的话，更新数据库重启的恢复
bin log: 影响数据库备份的数据

事务
---

1. 事务特性: (ACID)  原子性(undo log 回滚)、一致性(两个操作数据一致性)、隔离性、持久性(修改不因数据库重启而丢失，redo log)
2. 多事务同时执行，可能出现的问题: 脏读、不可重复读、幻读
3. 事务隔离级别(多个事务执行间的问题): 读未提交、读提交、可重复读、串行化
4. 不同隔离级别的区别: 
  - **读未提交**: 一个事务还未提交，他所做的修改可以被其他事务看到(没有视图概念，没解决任何并发问题)
  - **读提交**: 一个事务提交以后，他所做的修改才可以被其他事务看到(每个语句执行时创建的视图，解决了脏读问题)
  - **可重复读**: 一个事务执行过程看到的数据是一致的(视图实现),未提交的更改对其他事务不可见。(事务启动时创建视图实现，解决不可重复读问题)
  - **串行化**: 对应一个记录加读写锁，出现冲突时，后访问的事务必须等前一个事务执行完成才能继续执行(加锁实现，解决所有问题)
5. 配置方法: 启动参数transaction-isolation
6. 事务隔离的实现: 每条记录更新时都同时记录一个回滚操作，同一条记录在系统中可以存在多个版本，这就是数据库的多版本并发控制(MVCC)
7. 回滚日志什么时候删除: 系统判断当没有事务需要用到这些回滚日志的时候，回滚日志会被删除
8. 什么时候不需要了？当系统没有比这个回滚日志更早的read-view的时候
9. 为什么尽量不要使用长事务？长事务意味在系统里存在很老的事务视图，事务提交之前都会保存，导致占用大量存储空间，长事务还占用锁资源，可能拖垮库
10. 多事务同时执行可能出现的问题 [参考](https://uule.iteye.com/blog/1109647)
  - **脏读**: 一个事务修改了数据还未提交，另一个事务读取并使用了这个数据。当第一个事务回滚，另一个事务使用的数据就是脏数据(发生在`读未提交`) （由于其他事务没有提交造成）
  - **不可重复读**: 一个事务内多次读同一个数据，两次读之间数据被另一个事务修改，导致这两次读到的数据不一致。（由于其他事务提交造成）
  - **幻读**: 事务1对所有数据行执行修改，同时事务2添加了一条数据。事务1发现自己并没有实现全部数据的修改，好像发生了幻觉。(解决: 一个事务完成了处理前，其他事务不可以插入数据) （需要插入）
> mysql默认是可重复读，oracle默认是读提交
11. "autocommit"为事务的自动提交，设置为"off"时需要手动，开启和提交事务
```
begin # 或 start Transaction
update xxxx
commit # rollback
```
> 事务结束的时候，所持有的锁会释放

索引
---
#### 数据结构的考虑: 
- 哈希表:   
类似数组+链表，key的hash值确定在数组(桶)中的位置，出现hash冲突时，拉链。但这种对于范围查询不适用，需要全部扫描，比较适合**等值查询**
- 有序数组:   
查询利用二分查询,时间复杂度是O(log(N)); 也适用范围查询。但插入元素，需要移动后面的全部元素，效率很低。**适合静态存储引擎，不会修改数据了**
- 二叉树: 
  - 特点是，每个节点的左二子小于这个节点，右二子大于当前节点；这样查询的效率是O(log(N)),为了维持这个查询复杂度，需要保持这棵树是平衡二叉树，所以更新时间复杂度也是O(log(N))。
  - 实际索引使用的是多叉树(一个树有多个节点),原因是索引需要写磁盘，尽量要减少数据块的寻址，让树高小一点。 N叉树的N取决于数据块的大小。
- [跳表](https://juejin.im/post/57fa935b0e3dd90057c50fbc):  
redis中用于代替平衡树的结构，插入/删除/搜索都是O(log(n))。一种双向链表的发展，多层指向下一节点的指针。
- [LSM](https://juejin.im/post/5bbbf7615188255c59672125):  
相比下，B+树是随机磁盘访问，比顺序读写要慢。LSM顺序写，牺牲了一些读性能
  
#### 索引字段问题
- 主键索引(聚簇索引，叶子节点存的是整行数据)、非主键索引(二级索引，叶子节点存的是主键，所以还需要再查询一次主键索引的树)；**我们应尽量使用主键查询**。
- 而考虑占用空间，比如要用身份证号还是自增id做主键，显然主键越小，普通索引的叶子节点就越小，普通索引的占用空间也越小，所以自增主键更适合。
- 索引定位到page，page内部是一个有序数组，通过二分法查询。
> 通过普通索引查询到主键，再去主键索引树查询,叫做回表。

#### 自增主键的选择
- 选择的场景:
  - **性能**: 保持B+树的有序性，自增可减少页分裂和合并。
  - **空间**: 比如和身份证号做主键相比，因为非主键索引存的值是主键，主键较大，会比较占用存储空间。
- 不选择的场景:  
直接使用业务字段来作为主键: 只有一个索引且必须是唯一索引。

#### 死锁
- 事务A是有行1的锁，去申请行2的锁；事务B持有行2的锁，去申请行1的锁
- 持有对方需要的锁，并请求对应资源。解决: 执行死锁的回滚事务。对于InnoDB将持有最少行级排他锁的事务回滚

#### 一些索引
- 覆盖索引: 如果查询条件使用的是普通索引(或者是联合索引的最左原则)，查询结果是联合索引的字段或主键，不用回表，直接返回结果，减少IO磁盘读写读取正行数据。
- 最左前缀: 联合索引的最左N个字段，也可以是字符串索引的最左M个字符。
- 联合索引: 根据创建联合索引的顺序，以最左原则进行where检索，比如(age,name)以age=1或者age=1 and name='张三'可以使用索引，单以name='张三'不会使用索引，考虑存储空间问题，需要根据业务需求，将查找频繁的数据进行靠左创建索引。
- 索引下推: like 'hello%' and age >10检索，mysql5.6之前，会对匹配的数据进行回表查询，5.6以后，回先过滤掉age<10的数据，再进行回表查询，减少回表率，提升检索速度。
- 为什么用B+存储索引?(演变过程) [参考](https://juejin.im/entry/5bc1ea0a5188255c2f424209)
  - hash: 查询很快，适合固定值查询。不适合范围查询。
  - 有序数组: 查询和范围查询都很快，插入需要移动后面全部元素，效率较低。
  - 二叉搜索树: 存在极端情况，出现链表结构，搜索效率较低
  - 平衡二叉树: 解决了上面的问题，但对于索引大部分节点存在磁盘，每个节点是非连续的空间，每个节点的寻址操作是影响搜索速度的关键。基于此尽量需要减小树的高度
  - B树与B+树: 每个节点多放一些数据，对应数据库读取的最小单位页
    - B+树跟B树不同，B+树叶子节点冗余了所有非叶子节点的数据
    - B+树每个叶子节点增加了指向相邻的节点的指针
    - 优点:
      - 非叶子节点不会带上指向记录的指针，这样，一个块中可以容纳更多的索引项，一是可以降低树的高度。二是一个内部节点可以定位更多的叶子节点
      - 叶子节点间有序的链表，有利于范围查找。

#### 哪些方式无法应用到索引 [参考](https://www.cnblogs.com/wujianchao1988/archive/2012/05/16/2504221.html)
- ①函数  
- ②非左匹配 `like '%5400%'`; `like '5400%'`是可以的
- ③in , not in
- ④>, <, is null, is not null
- ⑤UNION

全局锁、表级锁、行级锁
---
#### 全局锁:
- 读整个数据库实例加锁。
- mysql提供加锁全局读锁的方法:Flush tables with read lock(FTWRL)这个命令可以使整个库处于只读状态。使用该命令之后，数据更新语句、数据定义语句和更新类事务的提交语句会被阻塞
- 使用场景: 全库逻辑备份
- 风险:
  - 如果在主库备份，在备份期间不能更新，业务停摆
  - 如果在从库备份，备份期间不能同步binlog，导致主从延迟，官方自带逻辑备份工具mysqldump,当mysqldump使用参数--single-transaction的时候，会启动一个事务，确保拿到一致性视图，而由于MVCC的支持，这个过程中数据是可以正常更新的
- 一致性读是好，但前提是引擎要支持隔离级别
- 如果全库只读为什么不使用set global readonly=true的方式？
  - readonly在有些系统被用来其他逻辑，比如判断主备库，所以修改的话影响较大
  - 异常机制有差异，FTWRL在发生异常时，会释放全局锁，readonly一直保持

#### 表级锁
- mysql有两种表级锁:一种是表锁；一种是元数据锁(meta data lock, MDL)
- MDL:不需要显示使用，访问一个表时字段加上
- 读写锁互斥，写写锁互斥，读读锁不互斥
- MDL会直到事务提交才会释放，在做表结构变更是，一定要小心不要导致阻塞线上查询和更新 
- 表级锁限制只能当前线程的操作，比如，线程A执行lock t1 read,t2 write ，则其他线程写t1。读写t2都会被阻塞
- 表锁分为：意向共享锁和意向排他锁，他们是一种锁的标志，为了使加表锁效率高，因为有存在任何行锁就不能加表锁，全表扫描有没有锁效率很低；这种意向锁是存在任何锁时，更新这个标志


#### 共享锁（行锁）
- 又称为读锁，S锁，多个是事务对与同一数据共享一把锁，都只能访问到数据，只能读不能修改
- 加锁释放锁方式:  
`select * from student where id =1 LOCK IN SHARE MODE`  
`commit/rollback`

#### 排他锁(行锁)
- 又称为写锁，X锁，不能与其他锁并存，如一个事务获取了一个数据行的 排他锁，其他事务不能获取该行的锁(共享锁，排他锁)，只有获取了该排他锁的事务可以对数据行读和修改
- 加锁释放锁方式L:  
自动: `delete / update / insert 默认加X锁`  
手动: `select * from student where id=1 FOR UPDATE`  
`commit / rollback`

#### 乐观锁与悲观锁 [参考](https://www.jianshu.com/p/f5ff017db62a)
- 悲观锁: 假设一定会发生冲突，所以每次拿数据之前都要加锁 (select for update 锁定当前行)
- 乐观锁: 每次拿数据都认为别人不会修改，只在提交时检查数据是不是已经被别人更新过了，乐观锁适用于读多写少的场景，这样可以提高吞吐量。(cas方式,字段值没有被其他线程修改，则更新操作)
  - 版本字段控制: 增加一个数字类型的字段'version',每次更新加1。 CAS方式实现
  - 使用时间戳，CAS，比较时间

> 悲观锁和乐观锁是用法，而不是划分的锁类型

#### 锁住了什么，行数据 / 列？
1. 没有用到索引时，排他锁，直接锁表，为什么？  
没有创建索引时，存在一个默认索引，扫描索引就所住了整张表
2. 锁住的是索引
3. 记录锁锁住的是该记录，where id = 4, 锁住的是id=4那一条记录(唯一性索引，等值查询，精确匹配)
4. 间隙锁(只在可重复读隔离级别中)，左开右开区间，比如1，4，7，10 。(-,1),(1,4),(4,7)...
对于等值查询没有命中和范围查询，锁住对应的范围；间隙锁间不互斥
5. 临键锁，左开右闭区间

分库分表
---
### 分表
- 单表数据量太大，影响sql执行性能

### 分库
- 并发量很高，单库并发量最好控制在每秒1000左右

### 中间件推荐
- Sharding-jdbc， 当当开源，client层方案
- Mycat，基于阿里的Cobar改造，proxy层解决方案

### 水平拆分与垂直拆分
- 水平: 就是把一个库的一个表数据弄到多个库的多个表中去，每个库的表结构一样，只不过每个表数据不同
- 垂直拆分: 表级别，将表字段拆分到不同的表中，单表最好控制在200万左右
  
### 两种分库分表方式
- 按range，比如时间范围,但会有近期热点访问问题
- 按每个字段，比如hash一下，分布均匀；会有扩容时的重新hash问题

主从复制
---
- 从库到主库来去binlog，然后在本地执行sql语句
- 半同步复制: 主库写入binlog以后，强制立即给从库，从库写完，至少一个返回ack，才算写成功

主从同步延迟问题
---
- 分库，降低主库的并发
- 重写代码，尽量不要写完马上查询